{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练数据...\n",
      "共有4575个图像被加载。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 62 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练模型...\n",
      "构建CNN\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3144: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 62)                31806     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 62)                0         \n",
      "=================================================================\n",
      "Total params: 2,148,862\n",
      "Trainable params: 2,148,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "进行图像增强处理...\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "143/143 [==============================] - 16s 113ms/step - loss: 2.8808 - acc: 0.2940\n",
      "Epoch 2/100\n",
      "143/143 [==============================] - 13s 91ms/step - loss: 1.8469 - acc: 0.4942\n",
      "Epoch 3/100\n",
      "143/143 [==============================] - 14s 96ms/step - loss: 1.4060 - acc: 0.5910\n",
      "Epoch 4/100\n",
      "143/143 [==============================] - 13s 93ms/step - loss: 1.1621 - acc: 0.6568\n",
      "Epoch 5/100\n",
      "143/143 [==============================] - 13s 93ms/step - loss: 0.9567 - acc: 0.7034\n",
      "Epoch 6/100\n",
      "143/143 [==============================] - 13s 94ms/step - loss: 0.8287 - acc: 0.7401\n",
      "Epoch 7/100\n",
      "143/143 [==============================] - 13s 94ms/step - loss: 0.7197 - acc: 0.7698\n",
      "Epoch 8/100\n",
      "143/143 [==============================] - 14s 95ms/step - loss: 0.6662 - acc: 0.7858\n",
      "Epoch 9/100\n",
      "143/143 [==============================] - 13s 93ms/step - loss: 0.5911 - acc: 0.8069 6s - l\n",
      "Epoch 10/100\n",
      "143/143 [==============================] - 13s 92ms/step - loss: 0.5286 - acc: 0.8280\n",
      "Epoch 11/100\n",
      "143/143 [==============================] - 13s 93ms/step - loss: 0.4940 - acc: 0.8441\n",
      "Epoch 12/100\n",
      "143/143 [==============================] - 13s 93ms/step - loss: 0.4707 - acc: 0.8442\n",
      "Epoch 13/100\n",
      "143/143 [==============================] - 13s 93ms/step - loss: 0.4386 - acc: 0.8544\n",
      "Epoch 14/100\n",
      "143/143 [==============================] - 13s 94ms/step - loss: 0.3925 - acc: 0.8719\n",
      "Epoch 15/100\n",
      "143/143 [==============================] - 13s 94ms/step - loss: 0.3880 - acc: 0.8743\n",
      "Epoch 16/100\n",
      "143/143 [==============================] - 13s 93ms/step - loss: 0.3538 - acc: 0.8896\n",
      "Epoch 17/100\n",
      "143/143 [==============================] - 13s 93ms/step - loss: 0.3332 - acc: 0.8909 1s - loss: 0.3329 -\n",
      "Epoch 18/100\n",
      "143/143 [==============================] - 13s 93ms/step - loss: 0.3288 - acc: 0.8903\n",
      "Epoch 19/100\n",
      "143/143 [==============================] - 13s 94ms/step - loss: 0.3050 - acc: 0.8960\n",
      "Epoch 20/100\n",
      "143/143 [==============================] - 14s 94ms/step - loss: 0.2811 - acc: 0.9095\n",
      "Epoch 21/100\n",
      "143/143 [==============================] - 13s 93ms/step - loss: 0.2940 - acc: 0.9056 0s - loss: 0.2911 - acc:\n",
      "Epoch 22/100\n",
      "143/143 [==============================] - 13s 93ms/step - loss: 0.2630 - acc: 0.9126\n",
      "Epoch 23/100\n",
      "143/143 [==============================] - 13s 93ms/step - loss: 0.2635 - acc: 0.9117\n",
      "Epoch 24/100\n",
      "143/143 [==============================] - 13s 93ms/step - loss: 0.2502 - acc: 0.9198\n",
      "Epoch 25/100\n",
      "143/143 [==============================] - 13s 93ms/step - loss: 0.2557 - acc: 0.9196\n",
      "Epoch 26/100\n",
      "143/143 [==============================] - 13s 91ms/step - loss: 0.2351 - acc: 0.9222 0s - loss: 0.2341 - acc: 0.92\n",
      "Epoch 27/100\n",
      "143/143 [==============================] - 13s 91ms/step - loss: 0.2365 - acc: 0.9187\n",
      "Epoch 28/100\n",
      "143/143 [==============================] - 13s 91ms/step - loss: 0.2117 - acc: 0.9292 1s - loss: 0.2074 - acc: 0 - ETA: 0s - loss: 0.2115 - a\n",
      "Epoch 29/100\n",
      "143/143 [==============================] - 14s 95ms/step - loss: 0.2178 - acc: 0.9259\n",
      "Epoch 30/100\n",
      "143/143 [==============================] - 13s 92ms/step - loss: 0.2108 - acc: 0.9362 1s - loss: 0.2095 \n",
      "Epoch 31/100\n",
      "143/143 [==============================] - 13s 91ms/step - loss: 0.2087 - acc: 0.9314\n",
      "Epoch 32/100\n",
      "143/143 [==============================] - 13s 92ms/step - loss: 0.1857 - acc: 0.9366\n",
      "Epoch 33/100\n",
      "143/143 [==============================] - 13s 92ms/step - loss: 0.1955 - acc: 0.9318\n",
      "Epoch 34/100\n",
      "143/143 [==============================] - 13s 92ms/step - loss: 0.1790 - acc: 0.9430\n",
      "Epoch 35/100\n",
      "143/143 [==============================] - 13s 91ms/step - loss: 0.1949 - acc: 0.9316\n",
      "Epoch 36/100\n",
      "143/143 [==============================] - 13s 91ms/step - loss: 0.1855 - acc: 0.9399\n",
      "Epoch 37/100\n",
      "143/143 [==============================] - 13s 91ms/step - loss: 0.1739 - acc: 0.9410\n",
      "Epoch 38/100\n",
      "143/143 [==============================] - 13s 91ms/step - loss: 0.1790 - acc: 0.9410 0s - loss: 0.1770 - acc: 0.9\n",
      "Epoch 39/100\n",
      "143/143 [==============================] - 13s 92ms/step - loss: 0.1779 - acc: 0.9421 1s - loss: 0.175\n",
      "Epoch 40/100\n",
      "143/143 [==============================] - 13s 91ms/step - loss: 0.1628 - acc: 0.9462 6s - loss: 0.1 - ETA: 4s - loss: 0.1589 - \n",
      "Epoch 41/100\n",
      "143/143 [==============================] - 13s 91ms/step - loss: 0.1731 - acc: 0.9373\n",
      "Epoch 42/100\n",
      "143/143 [==============================] - 13s 92ms/step - loss: 0.1505 - acc: 0.9521 1s - loss: 0.148\n",
      "Epoch 43/100\n",
      "143/143 [==============================] - 13s 92ms/step - loss: 0.1465 - acc: 0.9510\n",
      "Epoch 44/100\n",
      "143/143 [==============================] - 13s 92ms/step - loss: 0.1558 - acc: 0.9476\n",
      "Epoch 45/100\n",
      "143/143 [==============================] - 13s 91ms/step - loss: 0.1517 - acc: 0.9484\n",
      "Epoch 46/100\n",
      "143/143 [==============================] - 13s 91ms/step - loss: 0.1577 - acc: 0.9488\n",
      "Epoch 47/100\n",
      "143/143 [==============================] - 13s 91ms/step - loss: 0.1284 - acc: 0.9583 2s -\n",
      "Epoch 48/100\n",
      "143/143 [==============================] - 13s 92ms/step - loss: 0.1508 - acc: 0.9477 2s\n",
      "Epoch 49/100\n",
      "143/143 [==============================] - 13s 90ms/step - loss: 0.1502 - acc: 0.9517\n",
      "Epoch 50/100\n",
      "143/143 [==============================] - 12s 87ms/step - loss: 0.1381 - acc: 0.9545 1s - loss: 0.1360 \n",
      "Epoch 51/100\n",
      "143/143 [==============================] - 13s 89ms/step - loss: 0.1490 - acc: 0.9506\n",
      "Epoch 52/100\n",
      "143/143 [==============================] - 12s 87ms/step - loss: 0.1343 - acc: 0.9572 0s - loss: 0.1338 - \n",
      "Epoch 53/100\n",
      "143/143 [==============================] - 13s 88ms/step - loss: 0.1265 - acc: 0.9602\n",
      "Epoch 54/100\n",
      "143/143 [==============================] - 12s 87ms/step - loss: 0.1352 - acc: 0.9539\n",
      "Epoch 55/100\n",
      "143/143 [==============================] - 12s 87ms/step - loss: 0.1192 - acc: 0.9580\n",
      "Epoch 56/100\n",
      "143/143 [==============================] - 12s 87ms/step - loss: 0.1149 - acc: 0.9609\n",
      "Epoch 57/100\n",
      "143/143 [==============================] - 12s 82ms/step - loss: 0.1137 - acc: 0.9613\n",
      "Epoch 58/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1126 - acc: 0.9604\n",
      "Epoch 59/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1159 - acc: 0.9635\n",
      "Epoch 60/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1199 - acc: 0.9563\n",
      "Epoch 61/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1245 - acc: 0.9611\n",
      "Epoch 62/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1197 - acc: 0.9617\n",
      "Epoch 63/100\n",
      "143/143 [==============================] - 12s 82ms/step - loss: 0.1141 - acc: 0.9637\n",
      "Epoch 64/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1160 - acc: 0.9622\n",
      "Epoch 65/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1119 - acc: 0.9626\n",
      "Epoch 66/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1306 - acc: 0.9572\n",
      "Epoch 67/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1289 - acc: 0.9574\n",
      "Epoch 68/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0994 - acc: 0.9679\n",
      "Epoch 69/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1274 - acc: 0.9585\n",
      "Epoch 70/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1258 - acc: 0.9567\n",
      "Epoch 71/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1020 - acc: 0.9703\n",
      "Epoch 72/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1066 - acc: 0.9666\n",
      "Epoch 73/100\n",
      "143/143 [==============================] - 12s 80ms/step - loss: 0.1046 - acc: 0.9626\n",
      "Epoch 74/100\n",
      "143/143 [==============================] - 12s 82ms/step - loss: 0.0932 - acc: 0.9672 1s - loss: 0.\n",
      "Epoch 75/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0962 - acc: 0.9679\n",
      "Epoch 76/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1068 - acc: 0.9661\n",
      "Epoch 77/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1053 - acc: 0.9683\n",
      "Epoch 78/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0935 - acc: 0.9690\n",
      "Epoch 79/100\n",
      "143/143 [==============================] - 12s 82ms/step - loss: 0.1009 - acc: 0.9655 1s - loss: 0.\n",
      "Epoch 80/100\n",
      "143/143 [==============================] - 11s 80ms/step - loss: 0.0991 - acc: 0.9661\n",
      "Epoch 81/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0916 - acc: 0.9727\n",
      "Epoch 82/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1105 - acc: 0.9655\n",
      "Epoch 83/100\n",
      "143/143 [==============================] - 12s 82ms/step - loss: 0.1173 - acc: 0.9628\n",
      "Epoch 84/100\n",
      "143/143 [==============================] - 12s 82ms/step - loss: 0.0933 - acc: 0.9701\n",
      "Epoch 85/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1012 - acc: 0.9679\n",
      "Epoch 86/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0945 - acc: 0.9692\n",
      "Epoch 87/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0876 - acc: 0.9707\n",
      "Epoch 88/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0776 - acc: 0.9742\n",
      "Epoch 89/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0909 - acc: 0.9668\n",
      "Epoch 90/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0840 - acc: 0.9729\n",
      "Epoch 91/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0877 - acc: 0.9709\n",
      "Epoch 92/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0767 - acc: 0.9736\n",
      "Epoch 93/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0866 - acc: 0.9714\n",
      "Epoch 94/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0932 - acc: 0.9705\n",
      "Epoch 95/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.1192 - acc: 0.9641\n",
      "Epoch 96/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0971 - acc: 0.9685\n",
      "Epoch 97/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0957 - acc: 0.9696\n",
      "Epoch 98/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0891 - acc: 0.9722\n",
      "Epoch 99/100\n",
      "143/143 [==============================] - 12s 81ms/step - loss: 0.0821 - acc: 0.9722\n",
      "Epoch 100/100\n",
      "143/143 [==============================] - 12s 82ms/step - loss: 0.0925 - acc: 0.9722\n",
      "加载测试数据...\n",
      "共有2520个图像被加载。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2520/2520 [==============================] - 1s 435us/step\n",
      "测试loss: 0.197463，测试准确率：0.96\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "\n",
    "import utils\n",
    "import config\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # if read reserved model \n",
    "    if not config.load_model:\n",
    "        print('loading model...')\n",
    "        # load training data\n",
    "        train_images, train_labels = utils.load_data(config.train_data_dir)\n",
    "\n",
    "        # display image randomly\n",
    "        utils.display_traffic_signs(train_images, train_labels)\n",
    "\n",
    "        # process training model for input\n",
    "        X_train, y_train = utils.process_data(train_images, train_labels)\n",
    "\n",
    "        print('training model...')\n",
    "        # build CNN\n",
    "        cnn_model = utils.build_cnn()\n",
    "\n",
    "        # if image augmentation\n",
    "        if not config.data_augmentation:\n",
    "            print('no image augmentation...')\n",
    "\n",
    "            # traning model\n",
    "            cnn_model.fit(X_train, y_train,\n",
    "                          batch_size=config.batch_size,\n",
    "                          epochs=config.epochs)\n",
    "        else:\n",
    "            print('image augmentation...')\n",
    "            \n",
    "            datagen = ImageDataGenerator(\n",
    "                width_shift_range=0.1,  \n",
    "                height_shift_range=0.1,  \n",
    "                horizontal_flip=True  \n",
    "            )\n",
    "\n",
    "            # augmentation on training data\n",
    "            datagen.fit(X_train)\n",
    "            cnn_model.fit_generator(datagen.flow(X_train, y_train, batch_size=config.batch_size),\n",
    "                                    epochs=config.epochs,\n",
    "                                    workers=4)\n",
    "        # reserve trained model \n",
    "        cnn_model.save(config.model_file)\n",
    "\n",
    "    else:\n",
    "        print('loading trained model...')\n",
    "        if os.path.exists(config.model_file):\n",
    "            cnn_model = load_model(config.model_file)\n",
    "        else:\n",
    "            print('{}model file unexist'.format(config.model_file))\n",
    "            return\n",
    "\n",
    "    print('loading test data...')\n",
    "    test_images, test_labels = utils.load_data(config.test_data_dir)\n",
    "\n",
    "    # process traning data for model input\n",
    "    X_test, y_test = utils.process_data(test_images, test_labels)\n",
    "    test_loss, test_acc = cnn_model.evaluate(X_test, y_test)\n",
    "    print('test loss: {:.6f}，test accuracy：{:.2f}'.format(test_loss, test_acc))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
